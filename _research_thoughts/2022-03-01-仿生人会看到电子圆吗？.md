---
tag: [人工智能, 抽象]
---

真正的强人工智能应当具有两种能力：
1. 从物理世界中提出抽象的能力
2. 从抽象中发现规律的能力

我现在研究的Rule Mining就属于后者。当然，其他机器学习、神经网络都如此，只不过Rule Mining更偏重于可解释的逻辑系统。提出这种期望不仅仅代表着这样的智能体具有了更强的能力，还意味着它可以独立地生存，创造属于它自己的文明。我从来不认为AI是人类纯粹的工具或者纯粹的敌人，它应当是人类在自主进化的道路上的一次质变。

然而，目前为止，我还没有搞明白如何让机器完成第一个目标，也没有看到过其他人有类似的研究。因此，当前人们所能构造出来的AI都必须最终依附于人，在人类提供的环境中运行、成长，并被人类的能力所束缚。人类能够用抽象的几何元素描述世界，因此也希望AI能够使用基本的几何图形。但是考虑这样的一个问题：**把一个不具备几何知识的AI放在无人干预的自然环境当中，它能够通过它的眼睛看到圆形吗？**人类的数学起步于对“数”的认识，那么一个人造智能体可以自主总结出“数”的概念，从而重新发明数学吗？

在一次和Daniel的讨论中，我们意识到人的认知是有边界的，而这个边界则依赖于我们的感官。也就是说，我们所谓的抽象能力其实是由我们的物质组成先天决定的。Daniel总是喜欢引用维特跟斯坦的论断“文字是人类智慧的边界”，那么我们是如何理解文字中的概念的呢？一些基础的概念定义了我们日常生活的大部分内容，比如颜色、形状、气味、质地等等，这些描述性的内容可以定义我们所接触的几乎所有具有实体的物品。而仅当我们的感官被先进的仪器和设备放大之后，我们才能够理解并定义更多的物质存在，比如可见光波段之外的电磁波。那么，相应地，我们可以认为AI也必须在具有这些“感官”之后才可能进行抽象的理解。近年的机器视觉的发展就是很好的例证。从这个角度上说，AI的抽象能力能被也只能被它的生产者（可以是人类，也可以是它们自己）预先决定。

但是物质的前提只是必要条件，而不是全部的充分条件。缺失的条件是什么？是所谓的“算法”层面的因素吗？如果是，那么我们可以通过教会一只大猩猩这样的算法吗？如果不行，那么是不是说，这样的“算法”其实还是由我们比他们多出来的这些神经结构决定的？那么，所谓的意识，是不是也只是特定物质结构的副产品？至少，如果是这样的话，我们能有更大的把握说我们一定能在未来的某一天实现这样的强人工智能。

毕竟，这样的智能其实也并不“强”。